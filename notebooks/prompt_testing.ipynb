{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ByNoemie RAG - Prompt Testing Notebook\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. Basic LLM completion\n",
    "2. Vibe tag generation\n",
    "3. LangGraph workflows\n",
    "4. LangSmith tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "# Set API key (get free key at https://console.groq.com)\n",
    "os.environ['GROQ_API_KEY'] = 'your_key_here'  # Replace with actual key\n",
    "\n",
    "# Optional: Enable LangSmith tracing\n",
    "# os.environ['LANGCHAIN_API_KEY'] = 'your_langsmith_key'\n",
    "# os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "# os.environ['LANGCHAIN_PROJECT'] = 'bynoemie-testing'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic LLM Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.llm import create_llm_client\n",
    "\n",
    "# Create client (auto-detects provider)\n",
    "client = create_llm_client()\n",
    "print(f\"Using: {client.provider_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple completion\n",
    "response = client.chat(\n",
    "    system_prompt=\"You are a fashion expert.\",\n",
    "    user_prompt=\"Describe the vibe of a black sequin dress in 5 words.\"\n",
    ")\n",
    "\n",
    "print(f\"Response: {response.content}\")\n",
    "print(f\"Tokens: {response.usage}\")\n",
    "print(f\"Latency: {response.latency_ms:.0f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Rule-Based Vibe Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.vibe_generator import extract_vibes_from_product, get_vibe_scores\n",
    "\n",
    "# Sample product\n",
    "product = {\n",
    "    \"product_name\": \"Coco Dress\",\n",
    "    \"product_type\": \"Dress\",\n",
    "    \"product_description\": \"All eyes on you in the Coco Dress, an ultra-mini silhouette covered in oversized black sequins. Featuring slim straps and a daring open back, it's made for nights that sparkle.\",\n",
    "    \"colors_available\": \"Black, Gold\",\n",
    "    \"material\": \"Sequin\"\n",
    "}\n",
    "\n",
    "# Extract vibes\n",
    "vibes = extract_vibes_from_product(product)\n",
    "print(f\"Extracted vibes: {vibes}\")\n",
    "\n",
    "# Get scores\n",
    "scores = get_vibe_scores(product)\n",
    "print(f\"\\nTop vibe scores:\")\n",
    "for vibe, score in sorted(scores.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "    print(f\"  {vibe}: {score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LLM-Enhanced Vibe Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.llm import parse_json_response\n",
    "\n",
    "# Free-form prompt\n",
    "prompt = f\"\"\"Generate creative vibe tags for this product:\n",
    "\n",
    "Product: {product['product_name']}\n",
    "Description: {product['product_description']}\n",
    "Colors: {product['colors_available']}\n",
    "\n",
    "Create 8-10 evocative tags. Be creative and specific.\n",
    "Return JSON: {{\"vibe_tags\": [...], \"mood_summary\": \"...\"}}\"\"\"\n",
    "\n",
    "response = client.chat(\n",
    "    system_prompt=\"You are a creative fashion stylist. Generate memorable, evocative vibe tags.\",\n",
    "    user_prompt=prompt,\n",
    "    temperature=0.8\n",
    ")\n",
    "\n",
    "result = parse_json_response(response.content)\n",
    "print(f\"Vibe tags: {result.get('vibe_tags', [])}\")\n",
    "print(f\"Mood: {result.get('mood_summary', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. LangGraph Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.vibe_generator import create_vibe_generator\n",
    "\n",
    "# Create generator with LangGraph workflow\n",
    "generator = create_vibe_generator()\n",
    "\n",
    "# Generate vibes\n",
    "result = generator.generate(\n",
    "    product_id=\"test-001\",\n",
    "    product_name=product[\"product_name\"],\n",
    "    product_type=product[\"product_type\"],\n",
    "    description=product[\"product_description\"],\n",
    "    colors=product[\"colors_available\"],\n",
    "    material=product[\"material\"]\n",
    ")\n",
    "\n",
    "print(f\"Status: {result['status']}\")\n",
    "print(f\"Vibe Tags: {result['vibe_tags']}\")\n",
    "print(f\"Mood: {result.get('mood_summary', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. LangChain LCEL Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "# Get LangChain model\n",
    "llm = client.get_langchain_model()\n",
    "\n",
    "# Create parallel chains\n",
    "occasion_chain = ChatPromptTemplate.from_template(\"What occasion is a {item} best for? One word.\") | llm | StrOutputParser()\n",
    "mood_chain = ChatPromptTemplate.from_template(\"What mood does a {item} evoke? One word.\") | llm | StrOutputParser()\n",
    "\n",
    "parallel = RunnableParallel(\n",
    "    occasion=occasion_chain,\n",
    "    mood=mood_chain\n",
    ")\n",
    "\n",
    "result = parallel.invoke({\"item\": \"black sequin dress\"})\n",
    "print(f\"Occasion: {result['occasion']}\")\n",
    "print(f\"Mood: {result['mood']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample products\n",
    "products = [\n",
    "    {\n",
    "        \"product_name\": \"Coco Dress\",\n",
    "        \"product_description\": \"Ultra-mini sequin dress with open back\",\n",
    "        \"colors_available\": \"Black, Gold\",\n",
    "        \"material\": \"Sequin\"\n",
    "    },\n",
    "    {\n",
    "        \"product_name\": \"Tiara Satin Dress\",\n",
    "        \"product_description\": \"Feminine with a touch of fantasy\",\n",
    "        \"colors_available\": \"White, Champagne\",\n",
    "        \"material\": \"Silk, Satin\"\n",
    "    },\n",
    "    {\n",
    "        \"product_name\": \"Chantelle Heels\",\n",
    "        \"product_description\": \"Classic stiletto heels with elegant lines\",\n",
    "        \"colors_available\": \"Black, Nude\",\n",
    "        \"material\": \"Leather\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Rule-based batch\n",
    "from src.vibe_generator import process_products_batch\n",
    "\n",
    "results = process_products_batch(products)\n",
    "\n",
    "for r in results:\n",
    "    print(f\"\\n{r['product_name']}: {r['vibe_tags'][:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Compare Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "product = products[0]\n",
    "\n",
    "# Rule-based\n",
    "start = time.time()\n",
    "rule_vibes = extract_vibes_from_product(product)\n",
    "rule_time = (time.time() - start) * 1000\n",
    "\n",
    "print(f\"Rule-based ({rule_time:.0f}ms): {rule_vibes}\")\n",
    "\n",
    "# LLM\n",
    "start = time.time()\n",
    "llm_result = generator.generate(\n",
    "    product_name=product[\"product_name\"],\n",
    "    description=product[\"product_description\"],\n",
    "    colors=product[\"colors_available\"],\n",
    "    material=product[\"material\"]\n",
    ")\n",
    "llm_time = (time.time() - start) * 1000\n",
    "\n",
    "print(f\"LLM-based ({llm_time:.0f}ms): {llm_result['vibe_tags']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Save to data directory\n",
    "output_dir = Path('../data/outputs')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "output_file = output_dir / 'notebook_results.json'\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"Saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
